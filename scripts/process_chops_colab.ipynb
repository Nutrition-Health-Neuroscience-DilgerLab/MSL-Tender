{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0199204",
   "metadata": {},
   "source": [
    "# Pork Chop Background Removal with rembg + OCR\n",
    "\n",
    "This notebook processes pork chop images using:\n",
    "- **rembg** (U-2-Net model) for background removal\n",
    "- **Component detection** to separate chops from tags\n",
    "- **EasyOCR** to detect text (chops never have text, so text = tag-only images)\n",
    "\n",
    "**Current Status:**\n",
    "- ‚úÖ **1,490 total images** in database (all with `.jpg` extension)\n",
    "- ‚úÖ **All URL extensions standardized** to `.jpg` (lowercase)\n",
    "- üîÑ **Ready to process** all unprocessed images\n",
    "\n",
    "**Workflow:**\n",
    "1. Install dependencies (GPU-accelerated: rembg, EasyOCR)\n",
    "2. Configure credentials (embedded from .env)\n",
    "3. Fetch unprocessed images from Supabase\n",
    "4. Optional: Test with 5 images first\n",
    "5. Process all remaining unprocessed images\n",
    "6. Query & review failures, low-confidence, and text-detected images\n",
    "7. Reprocess failures with improved algorithm\n",
    "\n",
    "**‚ö° Enable GPU:** Runtime ‚Üí Change runtime type ‚Üí GPU ‚Üí Save\n",
    "\n",
    "**Quality Flags:**\n",
    "- Confidence > 70%: Clean chop ‚úÖ\n",
    "- Confidence 15-70%: Potential tag remnants ‚ö†Ô∏è\n",
    "- Confidence < 15%: Text detected, likely tag-only üî§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae411692",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rembg[gpu] pillow boto3 supabase requests tqdm scipy easyocr\n",
    "\n",
    "# Verify GPU availability\n",
    "import torch\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179ee176",
   "metadata": {},
   "source": [
    "## 2. Configure Credentials\n",
    "\n",
    "**Copy-paste your credentials from .env file below:**\n",
    "\n",
    "Find these in your local `.env` file (or `.env.local`):\n",
    "- `SUPABASE_URL`\n",
    "- `SUPABASE_SERVICE_KEY` (service_role key, not anon key)\n",
    "- `R2_ACCOUNT_ID`\n",
    "- `R2_ACCESS_KEY_ID`\n",
    "- `R2_SECRET_ACCESS_KEY`\n",
    "- `R2_BUCKET_NAME`\n",
    "- `NEXT_PUBLIC_R2_PUBLIC_URL`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c95292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Credentials embedded (notebook is in .gitignore - DO NOT COMMIT)\n",
    "credentials = \"\"\"\n",
    "SUPABASE_URL=https://qmecfslaeadrfdxlcekk.supabase.co\n",
    "SUPABASE_SERVICE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InFtZWNmc2xhZWFkcmZkeGxjZWtrIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc2NDcwNzYxMiwiZXhwIjoyMDgwMjgzNjEyfQ.I1Li1YcLU2cP347X5QPChj0yUBCqVPjnlh2hRhAoIgU\n",
    "R2_ACCOUNT_ID=5ea6d791d4f5c59cf5844ca8c8e4124e\n",
    "R2_ACCESS_KEY_ID=c378da4a7557d5645466245bfca9a779\n",
    "R2_SECRET_ACCESS_KEY=2a5f4a3f55989f21960874ac99ad2770997c507e282532fe2c0986e02414a04f\n",
    "R2_BUCKET_NAME=msl-tender-images\n",
    "NEXT_PUBLIC_R2_PUBLIC_URL=https://pub-54fd27572f2e4efc843722bee98239e0.r2.dev\n",
    "\"\"\"\n",
    "\n",
    "# Parse and set environment variables\n",
    "for line in credentials.strip().split('\\n'):\n",
    "    if '=' in line and not line.startswith('#'):\n",
    "        key, value = line.split('=', 1)\n",
    "        key = key.strip()\n",
    "        value = value.strip()\n",
    "        \n",
    "        # Map NEXT_PUBLIC_R2_PUBLIC_URL to R2_PUBLIC_URL\n",
    "        if key == 'NEXT_PUBLIC_R2_PUBLIC_URL':\n",
    "            os.environ['R2_PUBLIC_URL'] = value\n",
    "        else:\n",
    "            os.environ[key] = value\n",
    "\n",
    "# Verify all required credentials are set\n",
    "required = [\n",
    "    'SUPABASE_URL',\n",
    "    'SUPABASE_SERVICE_KEY',\n",
    "    'R2_ACCOUNT_ID',\n",
    "    'R2_ACCESS_KEY_ID',\n",
    "    'R2_SECRET_ACCESS_KEY',\n",
    "    'R2_BUCKET_NAME',\n",
    "    'R2_PUBLIC_URL'\n",
    "]\n",
    "\n",
    "missing = [key for key in required if not os.environ.get(key)]\n",
    "\n",
    "if missing:\n",
    "    print(f\"‚ùå Missing credentials: {', '.join(missing)}\")\n",
    "else:\n",
    "    print(\"‚úì All credentials configured successfully!\")\n",
    "    print(f\"  Supabase: {os.environ['SUPABASE_URL']}\")\n",
    "    print(f\"  R2 Bucket: {os.environ['R2_BUCKET_NAME']}\")\n",
    "    print(f\"  R2 Public URL: {os.environ['R2_PUBLIC_URL']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad02f3c5",
   "metadata": {},
   "source": [
    "## 3. Initialize Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3f249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supabase import create_client\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from rembg import remove\n",
    "from PIL import Image\n",
    "import io\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Initialize Supabase client\n",
    "supabase = create_client(\n",
    "    os.environ['SUPABASE_URL'],\n",
    "    os.environ['SUPABASE_SERVICE_KEY']\n",
    ")\n",
    "\n",
    "# Initialize R2 client (S3-compatible)\n",
    "r2 = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url=f\"https://{os.environ['R2_ACCOUNT_ID']}.r2.cloudflarestorage.com\",\n",
    "    aws_access_key_id=os.environ['R2_ACCESS_KEY_ID'],\n",
    "    aws_secret_access_key=os.environ['R2_SECRET_ACCESS_KEY'],\n",
    "    config=Config(signature_version='s3v4'),\n",
    "    region_name='auto'\n",
    ")\n",
    "\n",
    "# Initialize EasyOCR reader (English only, GPU enabled)\n",
    "import easyocr\n",
    "reader = easyocr.Reader(['en'], gpu=torch.cuda.is_available())\n",
    "\n",
    "print(\"‚úì Clients initialized\")\n",
    "print(\"‚úì OCR reader initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1195e35",
   "metadata": {},
   "source": [
    "## 4. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ddd59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "\n",
    "def extract_study_number_from_url(url: str) -> str:\n",
    "    \"\"\"Extract study number from filename (filename IS the study number).\"\"\"\n",
    "    filename = url.split('/')[-1]  # Get last segment\n",
    "    study_number = filename.rsplit('.', 1)[0]  # Remove extension\n",
    "    return study_number\n",
    "\n",
    "\n",
    "def download_image(url: str) -> Image.Image:\n",
    "    \"\"\"Download image from URL.\"\"\"\n",
    "    response = requests.get(url, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    return Image.open(io.BytesIO(response.content))\n",
    "\n",
    "\n",
    "def analyze_color_distribution(rgb_array: np.ndarray, mask: np.ndarray) -> dict:\n",
    "    \"\"\"\n",
    "    Analyze color distribution to distinguish meat from rulers/tags.\n",
    "    \n",
    "    Returns:\n",
    "        dict with color metrics:\n",
    "        - has_meat_tones: True if pink/red meat colors detected\n",
    "        - avg_saturation: Average color saturation (0-1)\n",
    "        - is_grayscale: True if mostly gray (like rulers)\n",
    "    \"\"\"\n",
    "    # Get only pixels within the mask\n",
    "    masked_pixels = rgb_array[mask > 0]\n",
    "    \n",
    "    if len(masked_pixels) == 0:\n",
    "        return {'has_meat_tones': False, 'avg_saturation': 0.0, 'is_grayscale': True}\n",
    "    \n",
    "    # Convert to HSV for better color analysis\n",
    "    # Calculate saturation and hue manually\n",
    "    r = masked_pixels[:, 0] / 255.0\n",
    "    g = masked_pixels[:, 1] / 255.0\n",
    "    b = masked_pixels[:, 2] / 255.0\n",
    "    \n",
    "    max_rgb = np.maximum(np.maximum(r, g), b)\n",
    "    min_rgb = np.minimum(np.minimum(r, g), b)\n",
    "    diff = max_rgb - min_rgb\n",
    "    \n",
    "    # Saturation calculation\n",
    "    saturation = np.where(max_rgb > 0, diff / max_rgb, 0)\n",
    "    avg_saturation = float(np.mean(saturation))\n",
    "    \n",
    "    # Hue calculation (for detecting red/pink tones)\n",
    "    hue = np.zeros_like(max_rgb)\n",
    "    # Red zone: hue 0-30 and 330-360 (in 0-360 scale)\n",
    "    mask_diff = diff > 0\n",
    "    mask_r = mask_diff & (max_rgb == r)\n",
    "    mask_g = mask_diff & (max_rgb == g)\n",
    "    mask_b = mask_diff & (max_rgb == b)\n",
    "    \n",
    "    hue[mask_r] = (60 * ((g[mask_r] - b[mask_r]) / diff[mask_r]) + 360) % 360\n",
    "    hue[mask_g] = (60 * ((b[mask_g] - r[mask_g]) / diff[mask_g]) + 120)\n",
    "    hue[mask_b] = (60 * ((r[mask_b] - g[mask_b]) / diff[mask_b]) + 240)\n",
    "    \n",
    "    # Meat tones: red/pink (hue 0-30 or 330-360) with moderate saturation\n",
    "    red_hue_mask = (hue < 30) | (hue > 330)\n",
    "    saturated_mask = saturation > 0.15\n",
    "    meat_tone_pixels = np.sum(red_hue_mask & saturated_mask)\n",
    "    has_meat_tones = (meat_tone_pixels / len(masked_pixels)) > 0.3\n",
    "    \n",
    "    # Grayscale check: low saturation across most pixels\n",
    "    is_grayscale = avg_saturation < 0.15\n",
    "    \n",
    "    return {\n",
    "        'has_meat_tones': bool(has_meat_tones),\n",
    "        'avg_saturation': float(avg_saturation),\n",
    "        'is_grayscale': bool(is_grayscale)\n",
    "    }\n",
    "\n",
    "\n",
    "def analyze_text_pattern(detected_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Analyze text patterns to distinguish rulers from tags.\n",
    "    \n",
    "    Returns:\n",
    "        dict with text pattern flags:\n",
    "        - has_sequential_numbers: True if text like \"1 2 3 4\" (ruler)\n",
    "        - has_alphanumeric_id: True if text like \"2304B00C0196D00\" (tag)\n",
    "        - has_measurement_marks: True if contains inch/cm markers\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    if not detected_text or len(detected_text) < 2:\n",
    "        return {\n",
    "            'has_sequential_numbers': False,\n",
    "            'has_alphanumeric_id': False,\n",
    "            'has_measurement_marks': False\n",
    "        }\n",
    "    \n",
    "    # Check for sequential numbers (ruler pattern)\n",
    "    numbers = re.findall(r'\\d+', detected_text)\n",
    "    has_sequential = False\n",
    "    if len(numbers) >= 3:\n",
    "        # Check if numbers are sequential (within 2 of each other)\n",
    "        nums = [int(n) for n in numbers[:5]]\n",
    "        diffs = [abs(nums[i+1] - nums[i]) for i in range(len(nums)-1)]\n",
    "        has_sequential = all(d <= 2 for d in diffs)\n",
    "    \n",
    "    # Check for alphanumeric study ID pattern (tag pattern)\n",
    "    has_alphanumeric_id = bool(re.search(r'[A-Z]\\d+[A-Z]\\d+', detected_text))\n",
    "    \n",
    "    # Check for measurement marks\n",
    "    has_measurement_marks = bool(re.search(r'\\b(in|inch|cm|mm)\\b', detected_text.lower()))\n",
    "    \n",
    "    return {\n",
    "        'has_sequential_numbers': bool(has_sequential),\n",
    "        'has_alphanumeric_id': bool(has_alphanumeric_id),\n",
    "        'has_measurement_marks': bool(has_measurement_marks)\n",
    "    }\n",
    "\n",
    "\n",
    "def process_image_with_rembg(image: Image.Image) -> tuple[Image.Image, dict]:\n",
    "    \"\"\"\n",
    "    Two-step processing:\n",
    "    1. Use rembg to remove blue background (transparent)\n",
    "    2. Use component detection to separate chop from paper tag\n",
    "    3. Apply blue edge cleanup for any residual artifacts\n",
    "    4. Collect enhanced metrics to distinguish chops from rulers/tags\n",
    "    \n",
    "    Returns:\n",
    "        (processed_image, metadata_dict)\n",
    "    \"\"\"\n",
    "    # Convert to RGB if needed\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    \n",
    "    # STEP 1: Remove background with rembg\n",
    "    output = remove(image)\n",
    "    \n",
    "    # Convert to numpy\n",
    "    img_array = np.array(output)\n",
    "    alpha = img_array[:, :, 3]\n",
    "    rgb = img_array[:, :, :3]\n",
    "    \n",
    "    # STEP 2: Component labeling to find chop (largest component)\n",
    "    # Create binary mask from alpha channel (anything not transparent)\n",
    "    foreground = alpha > 128\n",
    "    \n",
    "    # Label connected components\n",
    "    labeled, num_components = ndimage.label(foreground)\n",
    "    \n",
    "    if num_components == 0:\n",
    "        return None, {'confidence': 0.0, 'error': 'No foreground detected'}\n",
    "    \n",
    "    # Find sizes of all components\n",
    "    component_sizes = ndimage.sum(foreground, labeled, range(1, num_components + 1))\n",
    "    \n",
    "    # Keep only the largest component (the chop, not the tag)\n",
    "    largest_component = np.argmax(component_sizes) + 1\n",
    "    chop_mask = labeled == largest_component\n",
    "    \n",
    "    # STEP 2.5: Detect and remove bottom tags that may be connected to chop\n",
    "    # Analyze vertical distribution to find tags at edges\n",
    "    height, width = chop_mask.shape\n",
    "    row_densities = np.sum(chop_mask, axis=1) / width  # Density per row\n",
    "    \n",
    "    # Find significant gaps in vertical density (indicates tag separation)\n",
    "    # Look at bottom 30% of image for tags\n",
    "    bottom_third = int(height * 0.7)\n",
    "    if row_densities[bottom_third:].max() > 0:\n",
    "        # Check if there's a low-density gap suggesting a tag\n",
    "        smoothed = ndimage.uniform_filter1d(row_densities[bottom_third:], size=5)\n",
    "        \n",
    "        # Find first significant drop (< 20% density) from bottom\n",
    "        low_density = smoothed < 0.2\n",
    "        if low_density.any():\n",
    "            # Find the gap position\n",
    "            gap_start = bottom_third + np.where(low_density)[0][0]\n",
    "            \n",
    "            # Remove everything below the gap\n",
    "            chop_mask[gap_start:, :] = False\n",
    "    \n",
    "    # Get bounding box of the chop only\n",
    "    rows = np.any(chop_mask, axis=1)\n",
    "    cols = np.any(chop_mask, axis=0)\n",
    "    \n",
    "    if not rows.any() or not cols.any():\n",
    "        return None, {'confidence': 0.0, 'error': 'No chop detected'}\n",
    "    \n",
    "    y1, y2 = np.where(rows)[0][[0, -1]]\n",
    "    x1, x2 = np.where(cols)[0][[0, -1]]\n",
    "    \n",
    "    # Add 2% margin\n",
    "    height, width = chop_mask.shape\n",
    "    margin_x = int((x2 - x1) * 0.02)\n",
    "    margin_y = int((y2 - y1) * 0.02)\n",
    "    \n",
    "    x1 = max(0, x1 - margin_x)\n",
    "    y1 = max(0, y1 - margin_y)\n",
    "    x2 = min(width - 1, x2 + margin_x + 1)\n",
    "    y2 = min(height - 1, y2 + margin_y + 1)\n",
    "    \n",
    "    # Crop to chop bounding box\n",
    "    cropped_rgb = rgb[y1:y2, x1:x2]\n",
    "    cropped_mask = chop_mask[y1:y2, x1:x2]\n",
    "    \n",
    "    # STEP 3: Blue edge cleanup on the chop edges\n",
    "    # Detect blue edge pixels within the chop mask\n",
    "    is_blue = (cropped_rgb[:, :, 2] > cropped_rgb[:, :, 0] + 20) & \\\n",
    "              (cropped_rgb[:, :, 2] > cropped_rgb[:, :, 1] + 15)\n",
    "    \n",
    "    # Remove blue pixels from the chop mask\n",
    "    final_mask = cropped_mask & ~is_blue\n",
    "    \n",
    "    # Fill any holes (like punch holes in tags) before erosion\n",
    "    final_mask = ndimage.binary_fill_holes(final_mask)\n",
    "    \n",
    "    # Erode by 1 pixel to clean up edges\n",
    "    final_mask = ndimage.binary_erosion(final_mask, iterations=1)\n",
    "    \n",
    "    # Convert to alpha channel\n",
    "    final_alpha = (final_mask * 255).astype(np.uint8)\n",
    "    \n",
    "    # Reconstruct RGBA\n",
    "    final_array = np.dstack([cropped_rgb, final_alpha])\n",
    "    cleaned = Image.fromarray(final_array, 'RGBA')\n",
    "    \n",
    "    # Replace transparent background with white\n",
    "    final = Image.new('RGB', cleaned.size, (255, 255, 255))\n",
    "    final.paste(cleaned, mask=cleaned.split()[3])\n",
    "    \n",
    "    # Calculate confidence based on chop area\n",
    "    total_pixels = width * height\n",
    "    foreground_pixels = (x2 - x1) * (y2 - y1)\n",
    "    confidence = min(0.99, foreground_pixels / total_pixels)\n",
    "    \n",
    "    # STEP 4: Calculate enhanced metrics for ruler/tag detection\n",
    "    crop_width = x2 - x1\n",
    "    crop_height = y2 - y1\n",
    "    \n",
    "    # Aspect ratio (handles both orientations)\n",
    "    aspect_ratio = max(crop_width, crop_height) / max(min(crop_width, crop_height), 1)\n",
    "    \n",
    "    # Size metrics\n",
    "    crop_area = crop_width * crop_height\n",
    "    \n",
    "    # Color analysis\n",
    "    final_array_rgb = np.array(final)\n",
    "    color_metrics = analyze_color_distribution(cropped_rgb, final_mask)\n",
    "    \n",
    "    # STEP 5: Quality check - detect potential tags that slipped through\n",
    "    # Look for bright white rectangular regions at edges (typical of tags)\n",
    "    gray = np.mean(final_array_rgb, axis=2)\n",
    "    \n",
    "    # Check bottom 20% for bright regions\n",
    "    crop_height_final = final_array_rgb.shape[0]\n",
    "    bottom_region = gray[int(crop_height_final * 0.8):, :]\n",
    "    bright_pixels = np.sum(bottom_region > 240)  # Very bright pixels\n",
    "    bottom_pixels = bottom_region.size\n",
    "    \n",
    "    # Flag if > 10% of bottom region is very bright (likely a tag)\n",
    "    has_tag_warning = (bright_pixels / bottom_pixels) > 0.1 if bottom_pixels > 0 else False\n",
    "    \n",
    "    # STEP 6: OCR text detection - chops NEVER have text\n",
    "    # Run OCR on the processed image to detect any text\n",
    "    try:\n",
    "        ocr_results = reader.readtext(final_array_rgb, detail=0)  # detail=0 returns just text\n",
    "        detected_text = ' '.join(ocr_results).strip()\n",
    "        has_text = len(detected_text) > 0\n",
    "        \n",
    "        # Analyze text patterns\n",
    "        text_patterns = analyze_text_pattern(detected_text)\n",
    "        \n",
    "        # If significant text detected (more than 2 characters), likely a tag-only image\n",
    "        if has_text and len(detected_text) > 2:\n",
    "            has_tag_warning = True\n",
    "            confidence *= 0.1  # Very low confidence for text detection (< 10%)\n",
    "    except Exception as e:\n",
    "        # OCR failed, continue without text detection\n",
    "        has_text = False\n",
    "        detected_text = \"\"\n",
    "        text_patterns = {\n",
    "            'has_sequential_numbers': False,\n",
    "            'has_alphanumeric_id': False,\n",
    "            'has_measurement_marks': False\n",
    "        }\n",
    "    \n",
    "    # STEP 7: Composite \"likely invalid\" flags\n",
    "    # Extreme aspect ratio = likely ruler (> 4:1 in either direction)\n",
    "    is_extreme_aspect_ratio = aspect_ratio > 4.0\n",
    "    \n",
    "    # Too small = likely tag fragment\n",
    "    is_too_small = crop_width < 300 or crop_height < 300\n",
    "    \n",
    "    # Ruler characteristics: elongated + gray + sequential numbers\n",
    "    likely_ruler = (\n",
    "        is_extreme_aspect_ratio and \n",
    "        color_metrics['is_grayscale'] and \n",
    "        text_patterns.get('has_sequential_numbers', False)\n",
    "    )\n",
    "    \n",
    "    # Tag characteristics: small + has alphanumeric ID or white with text\n",
    "    likely_tag = (\n",
    "        is_too_small or \n",
    "        (has_tag_warning and text_patterns.get('has_alphanumeric_id', False))\n",
    "    )\n",
    "    \n",
    "    # Overall validity flag\n",
    "    likely_invalid = likely_ruler or likely_tag or (is_extreme_aspect_ratio and not color_metrics['has_meat_tones'])\n",
    "    \n",
    "    # Reduce confidence if tag detected (but not text, already handled above)\n",
    "    if has_tag_warning and not has_text:\n",
    "        confidence *= 0.7  # Flag with lower confidence for review\n",
    "    \n",
    "    metadata = {\n",
    "        'crop_x1': int(x1),\n",
    "        'crop_y1': int(y1),\n",
    "        'crop_x2': int(x2),\n",
    "        'crop_y2': int(y2),\n",
    "        'crop_width': int(crop_width),\n",
    "        'crop_height': int(crop_height),\n",
    "        'crop_area': int(crop_area),\n",
    "        'aspect_ratio': float(aspect_ratio),\n",
    "        'confidence': float(confidence),\n",
    "        'has_tag_warning': bool(has_tag_warning),\n",
    "        'has_text': bool(has_text),\n",
    "        'detected_text': str(detected_text[:100] if detected_text else \"\"),\n",
    "        'has_meat_tones': bool(color_metrics['has_meat_tones']),\n",
    "        'avg_saturation': float(color_metrics['avg_saturation']),\n",
    "        'is_grayscale': bool(color_metrics['is_grayscale']),\n",
    "        'has_sequential_numbers': bool(text_patterns['has_sequential_numbers']),\n",
    "        'has_alphanumeric_id': bool(text_patterns['has_alphanumeric_id']),\n",
    "        'likely_ruler': bool(likely_ruler),\n",
    "        'likely_tag': bool(likely_tag),\n",
    "        'likely_invalid': bool(likely_invalid)\n",
    "    }\n",
    "    \n",
    "    return final, metadata\n",
    "\n",
    "\n",
    "def upload_to_r2(image: Image.Image, study_number: str, filename: str) -> str:\n",
    "    \"\"\"Upload processed image to R2 and return public URL.\"\"\"\n",
    "    # Convert image to JPEG bytes\n",
    "    buffer = io.BytesIO()\n",
    "    image.save(buffer, format='JPEG', quality=95, optimize=True)\n",
    "    buffer.seek(0)\n",
    "    \n",
    "    # Upload to R2: use study_number as folder (which is the filename without extension)\n",
    "    key = f\"processed/{study_number}.jpg\"  # Flat structure since study_number IS the unique ID\n",
    "    r2.put_object(\n",
    "        Bucket=os.environ['R2_BUCKET_NAME'],\n",
    "        Key=key,\n",
    "        Body=buffer.getvalue(),\n",
    "        ContentType='image/jpeg',\n",
    "        CacheControl='public, max-age=31536000, immutable'\n",
    "    )\n",
    "    \n",
    "    # Return public URL\n",
    "    return f\"{os.environ['R2_PUBLIC_URL']}/{key}\"\n",
    "\n",
    "\n",
    "def update_database(image_id: int, processed_url: str, metadata: dict):\n",
    "    \"\"\"Update database with processed image information and enhanced metrics.\"\"\"\n",
    "    supabase.table('sample_images').update({\n",
    "        'processed_image_url': processed_url,\n",
    "        'crop_x1': metadata['crop_x1'],\n",
    "        'crop_y1': metadata['crop_y1'],\n",
    "        'crop_x2': metadata['crop_x2'],\n",
    "        'crop_y2': metadata['crop_y2'],\n",
    "        'crop_width': metadata['crop_width'],\n",
    "        'crop_height': metadata['crop_height'],\n",
    "        'aspect_ratio': metadata['aspect_ratio'],\n",
    "        'crop_confidence': metadata['confidence'],\n",
    "        'has_meat_tones': metadata['has_meat_tones'],\n",
    "        'avg_saturation': metadata['avg_saturation'],\n",
    "        'is_grayscale': metadata['is_grayscale'],\n",
    "        'has_sequential_numbers': metadata['has_sequential_numbers'],\n",
    "        'likely_ruler': metadata['likely_ruler'],\n",
    "        'likely_tag': metadata['likely_tag'],\n",
    "        'likely_invalid': metadata['likely_invalid'],\n",
    "        'crop_processed': True,\n",
    "        'processed_at': 'now()'\n",
    "    }).eq('id', image_id).execute()\n",
    "\n",
    "print(\"‚úì Helper functions defined\")\n",
    "print(\"‚úì Enhanced metrics enabled:\")\n",
    "print(\"  - Aspect ratio analysis (handles all orientations)\")\n",
    "print(\"  - Color distribution (meat tones vs grayscale)\")\n",
    "print(\"  - Text pattern detection (rulers vs tags)\")\n",
    "print(\"  - Composite validity flags (likely_ruler, likely_tag, likely_invalid)\")\n",
    "print(\"  - All values properly converted for JSON serialization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f52ff4",
   "metadata": {},
   "source": [
    "## 5. Test Mode: Process First 5 Images (Optional)\n",
    "\n",
    "Process first 5 images as a test to verify everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581051e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch unprocessed images (test with first 5)\n",
    "response = supabase.table('sample_images') \\\n",
    "    .select('id, image_url') \\\n",
    "    .or_('crop_processed.is.null,crop_processed.eq.false') \\\n",
    "    .not_.is_('image_url', 'null') \\\n",
    "    .limit(10000) \\\n",
    "    .execute()\n",
    "\n",
    "images_to_process = response.data\n",
    "print(f\"Found {len(images_to_process)} unprocessed images\")\n",
    "print(f\"Testing with first 5 images...\\n\")\n",
    "\n",
    "# Test with first 5 images\n",
    "test_images = images_to_process[:5]\n",
    "\n",
    "results = {\n",
    "    'success': 0,\n",
    "    'failed': 0,\n",
    "    'tag_warnings': 0,\n",
    "    'text_detected': 0,\n",
    "    'errors': []\n",
    "}\n",
    "\n",
    "for img_data in tqdm(test_images, desc=\"Processing test images\"):\n",
    "    try:\n",
    "        # Download original image\n",
    "        original = download_image(img_data['image_url'])\n",
    "        \n",
    "        # Process with rembg\n",
    "        processed, metadata = process_image_with_rembg(original)\n",
    "        \n",
    "        if processed is None:\n",
    "            results['failed'] += 1\n",
    "            results['errors'].append({\n",
    "                'id': img_data['id'],\n",
    "                'error': metadata.get('error', 'Unknown error')\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Track tag warnings and text detection\n",
    "        if metadata.get('has_tag_warning', False):\n",
    "            results['tag_warnings'] += 1\n",
    "        if metadata.get('has_text', False):\n",
    "            results['text_detected'] += 1\n",
    "        \n",
    "        # Extract study number and filename\n",
    "        study_number = extract_study_number_from_url(img_data['image_url'])\n",
    "        filename = img_data['image_url'].split('/')[-1]\n",
    "        \n",
    "        # Upload to R2\n",
    "        processed_url = upload_to_r2(processed, study_number, filename)\n",
    "        \n",
    "        # Update database\n",
    "        update_database(img_data['id'], processed_url, metadata)\n",
    "        \n",
    "        results['success'] += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        results['failed'] += 1\n",
    "        results['errors'].append({\n",
    "            'id': img_data['id'],\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "print(f\"\\n‚úì Test complete: {results['success']} succeeded, {results['failed']} failed\")\n",
    "if results['tag_warnings'] > 0:\n",
    "    print(f\"‚ö†Ô∏è  {results['tag_warnings']} images flagged with potential tags (check confidence < 70%)\")\n",
    "if results['text_detected'] > 0:\n",
    "    print(f\"üî§ {results['text_detected']} images with text detected (likely tag-only, confidence < 15%)\")\n",
    "if results['errors']:\n",
    "    print(\"\\nErrors:\")\n",
    "    for err in results['errors']:\n",
    "        print(f\"  ID {err['id']}: {err['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90be1de8",
   "metadata": {},
   "source": [
    "## 6. View Test Results\n",
    "\n",
    "Check the processed images at: **https://msl-tender.vercel.app/admin/crop-test**\n",
    "\n",
    "Verify:\n",
    "- ‚úÖ Blue background completely removed\n",
    "- ‚úÖ Chop edges preserved perfectly\n",
    "- ‚úÖ No blue \"mohawk\" artifacts\n",
    "- ‚úÖ Paper tags excluded\n",
    "- ‚úÖ Fat/meat coloring intact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0819d239",
   "metadata": {},
   "source": [
    "## 7. Process All Remaining Images\n",
    "\n",
    "‚ö†Ô∏è **Run this cell only after verifying test results look good!**\n",
    "\n",
    "This will process ALL remaining unprocessed images (~485 images after cleanup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2159feaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all unprocessed images again (in case test images are now processed)\n",
    "response = supabase.table('sample_images') \\\n",
    "    .select('id, image_url') \\\n",
    "    .or_('crop_processed.is.null,crop_processed.eq.false') \\\n",
    "    .not_.is_('image_url', 'null') \\\n",
    "    .limit(10000) \\\n",
    "    .execute()\n",
    "\n",
    "all_images = response.data\n",
    "print(f\"Processing {len(all_images)} images...\\n\")\n",
    "\n",
    "results = {\n",
    "    'success': 0,\n",
    "    'failed': 0,\n",
    "    'missing_originals': 0,\n",
    "    'missing_ids': [],\n",
    "    'tag_warnings': 0,\n",
    "    'text_detected': 0,\n",
    "    'errors': []\n",
    "}\n",
    "\n",
    "# Process with progress bar\n",
    "for img_data in tqdm(all_images, desc=\"Processing all images\"):\n",
    "    try:\n",
    "        # Download original image\n",
    "        original = download_image(img_data['image_url'])\n",
    "        \n",
    "        # Process with rembg\n",
    "        processed, metadata = process_image_with_rembg(original)\n",
    "        \n",
    "        if processed is None:\n",
    "            results['failed'] += 1\n",
    "            results['errors'].append({\n",
    "                'id': img_data['id'],\n",
    "                'error': metadata.get('error', 'Unknown error')\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Track tag warnings and text detection\n",
    "        if metadata.get('has_tag_warning', False):\n",
    "            results['tag_warnings'] += 1\n",
    "        if metadata.get('has_text', False):\n",
    "            results['text_detected'] += 1\n",
    "        \n",
    "        # Extract study number and filename\n",
    "        study_number = extract_study_number_from_url(img_data['image_url'])\n",
    "        filename = img_data['image_url'].split('/')[-1]\n",
    "        \n",
    "        # Upload to R2\n",
    "        processed_url = upload_to_r2(processed, study_number, filename)\n",
    "        \n",
    "        # Update database\n",
    "        update_database(img_data['id'], processed_url, metadata)\n",
    "        \n",
    "        results['success'] += 1\n",
    "        \n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        if e.response.status_code == 404:\n",
    "            # Original image not found in R2\n",
    "            results['missing_originals'] += 1\n",
    "            results['missing_ids'].append(img_data['id'])\n",
    "        else:\n",
    "            results['failed'] += 1\n",
    "            results['errors'].append({\n",
    "                'id': img_data['id'],\n",
    "                'error': str(e)\n",
    "            })\n",
    "    except Exception as e:\n",
    "        results['failed'] += 1\n",
    "        results['errors'].append({\n",
    "            'id': img_data['id'],\n",
    "            'error': str(e)\n",
    "        })\n",
    "    \n",
    "    # Print progress every 100 images\n",
    "    if (results['success'] + results['failed'] + results['missing_originals']) % 100 == 0:\n",
    "        print(f\"Progress: {results['success']} succeeded, {results['failed']} failed, {results['missing_originals']} missing originals, {results['tag_warnings']} warnings, {results['text_detected']} text\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(f\"‚úì COMPLETE: {results['success']} succeeded, {results['failed']} failed\")\n",
    "if results['missing_originals'] > 0:\n",
    "    print(f\"‚ö†Ô∏è  {results['missing_originals']} images with missing R2 originals (404)\")\n",
    "    print(f\"   IDs stored in results['missing_ids'] for cleanup\")\n",
    "if results['tag_warnings'] > 0:\n",
    "    print(f\"‚ö†Ô∏è  {results['tag_warnings']} images flagged with potential tags\")\n",
    "    print(f\"   ‚Üí Review images with confidence < 70% at /admin/crop-test\")\n",
    "if results['text_detected'] > 0:\n",
    "    print(f\"üî§ {results['text_detected']} images with text detected (likely tag-only)\")\n",
    "    print(f\"   ‚Üí Review images with confidence < 15% at /admin/crop-test\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if results['errors']:\n",
    "    print(f\"\\n{len(results['errors'])} errors occurred:\")\n",
    "    for err in results['errors'][:10]:  # Show first 10 errors\n",
    "        print(f\"  ID {err['id']}: {err['error']}\")\n",
    "    if len(results['errors']) > 10:\n",
    "        print(f\"  ... and {len(results['errors']) - 10} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78da3e9e",
   "metadata": {},
   "source": [
    "## 8. Review Results & Identify Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7653ff",
   "metadata": {},
   "source": [
    "### 8a. Low-Confidence Images (Tag Remnants)\n",
    "\n",
    "Query images that were processed but flagged with low confidence (< 70%), which indicates potential tags that slipped through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd7c401",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.14.0' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/rndpi/AppData/Local/Programs/Python/Python314/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Query images with low confidence (likely tag warnings)\n",
    "response = supabase.table('sample_images') \\\n",
    "    .select('id, image_url, crop_confidence, processed_image_url') \\\n",
    "    .eq('crop_processed', True) \\\n",
    "    .lt('crop_confidence', 0.70) \\\n",
    "    .order('crop_confidence') \\\n",
    "    .execute()\n",
    "\n",
    "flagged_images = response.data\n",
    "print(f\"Found {len(flagged_images)} images with confidence < 70%\\n\")\n",
    "\n",
    "if len(flagged_images) > 0:\n",
    "    print(\"Low-confidence images (review these for tag issues):\")\n",
    "    for img in flagged_images[:20]:  # Show first 20\n",
    "        print(f\"  ID: {img['id']}, Confidence: {img['crop_confidence']:.1%}\")\n",
    "        print(f\"     Processed: {img['processed_image_url']}\")\n",
    "        print(f\"     Original:  {img['image_url']}\\n\")\n",
    "    \n",
    "    if len(flagged_images) > 20:\n",
    "        print(f\"  ... and {len(flagged_images) - 20} more\")\n",
    "    \n",
    "    print(f\"\\nüí° View all at: https://msl-tender.vercel.app/admin/crop-test\")\n",
    "    print(f\"   Filter by confidence < 70% to review flagged images\")\n",
    "else:\n",
    "    print(\"‚úì No low-confidence images found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f624c726",
   "metadata": {},
   "source": [
    "### 8b. Text-Only Images (Tag-Only, No Chop)\n",
    "\n",
    "Query images where OCR detected text, indicating tag-only images with no actual chop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064c37ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query images with extremely low confidence (< 15%), indicating text detection\n",
    "response = supabase.table('sample_images') \\\n",
    "    .select('id, image_url, crop_confidence, processed_image_url') \\\n",
    "    .eq('crop_processed', True) \\\n",
    "    .lt('crop_confidence', 0.15) \\\n",
    "    .order('crop_confidence') \\\n",
    "    .execute()\n",
    "\n",
    "text_images = response.data\n",
    "print(f\"Found {len(text_images)} images with confidence < 15% (likely text-only/tag-only)\\n\")\n",
    "\n",
    "if len(text_images) > 0:\n",
    "    print(\"‚ö†Ô∏è TEXT-ONLY IMAGES (no chop detected):\")\n",
    "    for img in text_images[:20]:  # Show first 20\n",
    "        print(f\"  ID: {img['id']}, Confidence: {img['crop_confidence']:.1%}\")\n",
    "        print(f\"     Processed: {img['processed_image_url']}\")\n",
    "        print(f\"     Original:  {img['image_url']}\\n\")\n",
    "    \n",
    "    if len(text_images) > 20:\n",
    "        print(f\"  ... and {len(text_images) - 20} more\")\n",
    "    \n",
    "    print(f\"\\nüí° These images should likely be excluded from the dataset\")\n",
    "    print(f\"   or marked for manual review to verify they're not chops.\")\n",
    "else:\n",
    "    print(\"‚úì No text-only images found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfc6952",
   "metadata": {},
   "source": [
    "## 9. Reprocess Failed Images\n",
    "\n",
    "Run this cell to reprocess all images that failed during the batch run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b3dae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current failure count\n",
    "response = supabase.table('sample_images') \\\n",
    "    .select('id', count='exact') \\\n",
    "    .or_('crop_processed.is.null,crop_processed.eq.false') \\\n",
    "    .not_.is_('image_url', 'null') \\\n",
    "    .execute()\n",
    "\n",
    "failure_count = response.count\n",
    "print(f\"Current failures: {failure_count}\")\n",
    "\n",
    "if failure_count > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è  {failure_count} images need reprocessing\")\n",
    "    print(f\"   Run the 'Reprocess Failed Images' cell below to retry them\")\n",
    "else:\n",
    "    print(\"‚úì All images processed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d170bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch failed images (crop_processed = false or null)\n",
    "response = supabase.table('sample_images') \\\n",
    "    .select('id, image_url') \\\n",
    "    .or_('crop_processed.is.null,crop_processed.eq.false') \\\n",
    "    .not_.is_('image_url', 'null') \\\n",
    "    .execute()\n",
    "\n",
    "failed_images = response.data\n",
    "print(f\"Reprocessing {len(failed_images)} failed images...\\n\")\n",
    "\n",
    "if len(failed_images) == 0:\n",
    "    print(\"‚úì No failed images to reprocess!\")\n",
    "else:\n",
    "    results = {\n",
    "        'success': 0,\n",
    "        'failed': 0,\n",
    "        'tag_warnings': 0,\n",
    "        'text_detected': 0,\n",
    "        'errors': []\n",
    "    }\n",
    "    \n",
    "    for img_data in tqdm(failed_images, desc=\"Reprocessing failed images\"):\n",
    "        try:\n",
    "            original = download_image(img_data['image_url'])\n",
    "            processed, metadata = process_image_with_rembg(original)\n",
    "            \n",
    "            if processed is None:\n",
    "                results['failed'] += 1\n",
    "                results['errors'].append({\n",
    "                    'id': img_data['id'],\n",
    "                    'error': metadata.get('error', 'Unknown error')\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            if metadata.get('has_tag_warning', False):\n",
    "                results['tag_warnings'] += 1\n",
    "            if metadata.get('has_text', False):\n",
    "                results['text_detected'] += 1\n",
    "                results['tag_warnings'] += 1\n",
    "            \n",
    "            study_number = extract_study_number_from_url(img_data['image_url'])\n",
    "            filename = img_data['image_url'].split('/')[-1]\n",
    "            processed_url = upload_to_r2(processed, study_number, filename)\n",
    "            update_database(img_data['id'], processed_url, metadata)\n",
    "            \n",
    "            results['success'] += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            results['failed'] += 1\n",
    "            results['errors'].append({\n",
    "                'id': img_data['id'],\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    print(f\"\\n‚úì Reprocessing complete: {results['success']} succeeded, {results['failed']} still failed\")\n",
    "    if results['tag_warnings'] > 0:\n",
    "        print(f\"‚ö†Ô∏è  {results['tag_warnings']} flagged with potential tags\")\n",
    "    if results['text_detected'] > 0:\n",
    "        print(f\"üî§ {results['text_detected']} with text detected (tag-only)\")\n",
    "    \n",
    "    if results['errors']:\n",
    "        print(f\"\\nPersistent errors ({len(results['errors'])}):\")\n",
    "        for err in results['errors'][:10]:\n",
    "            print(f\"  ID {err['id']}: {err['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10f3445",
   "metadata": {},
   "source": [
    "### 9b. Retry Single Failed Image by ID\n",
    "\n",
    "If you have a specific image ID that failed (e.g., from a \"Server disconnected\" error), retry just that one image here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc75417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste the failed image ID here\n",
    "failed_image_id = '72c97211-e5c5-4956-ac0d-bdfa6ed20637'\n",
    "\n",
    "print(f\"Retrying image ID: {failed_image_id}\\n\")\n",
    "\n",
    "try:\n",
    "    # Fetch the specific image\n",
    "    response = supabase.table('sample_images') \\\n",
    "        .select('id, image_url') \\\n",
    "        .eq('id', failed_image_id) \\\n",
    "        .execute()\n",
    "    \n",
    "    if not response.data or len(response.data) == 0:\n",
    "        print(f\"‚ùå Image ID not found in database\")\n",
    "    else:\n",
    "        img_data = response.data[0]\n",
    "        print(f\"Found image: {img_data['image_url']}\\n\")\n",
    "        \n",
    "        # Process the image\n",
    "        original = download_image(img_data['image_url'])\n",
    "        processed, metadata = process_image_with_rembg(original)\n",
    "        \n",
    "        if processed is None:\n",
    "            print(f\"‚ùå Processing failed: {metadata.get('error', 'Unknown error')}\")\n",
    "        else:\n",
    "            # Extract study number and filename\n",
    "            study_number = extract_study_number_from_url(img_data['image_url'])\n",
    "            filename = img_data['image_url'].split('/')[-1]\n",
    "            \n",
    "            # Upload to R2\n",
    "            processed_url = upload_to_r2(processed, study_number, filename)\n",
    "            \n",
    "            # Update database\n",
    "            update_database(img_data['id'], processed_url, metadata)\n",
    "            \n",
    "            print(\"‚úÖ SUCCESS!\")\n",
    "            print(f\"   Processed URL: {processed_url}\")\n",
    "            print(f\"   Confidence: {metadata['confidence']:.1%}\")\n",
    "            print(f\"   Aspect Ratio: {metadata['aspect_ratio']:.1f}:1\")\n",
    "            print(f\"   Likely Invalid: {metadata['likely_invalid']}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {str(e)}\")\n",
    "    print(f\"\\nIf this is another network error, wait a moment and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2ad597",
   "metadata": {},
   "source": [
    "## 10. Summary Statistics\n",
    "\n",
    "Get overall processing statistics across all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1610f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get final statistics\n",
    "stats = supabase.table('sample_images') \\\n",
    "    .select('crop_processed', count='exact') \\\n",
    "    .execute()\n",
    "\n",
    "processed_count = supabase.table('sample_images') \\\n",
    "    .select('id', count='exact') \\\n",
    "    .eq('crop_processed', True) \\\n",
    "    .execute()\n",
    "\n",
    "total = stats.count\n",
    "processed = processed_count.count\n",
    "remaining = total - processed\n",
    "\n",
    "print(f\"\\nFinal Statistics:\")\n",
    "print(f\"  Total images: {total}\")\n",
    "print(f\"  Processed: {processed} ({100*processed/total:.1f}%)\")\n",
    "print(f\"  Remaining: {remaining}\")\n",
    "print(f\"\\nView results at: https://msl-tender.vercel.app/admin/crop-test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c707d3",
   "metadata": {},
   "source": [
    "## 11. Query Likely Invalid Images (Rulers/Tags)\n",
    "\n",
    "Use the enhanced metrics to find images flagged as likely rulers or tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eb9484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query images flagged as likely invalid (rulers or tags)\n",
    "response = supabase.table('sample_images') \\\n",
    "    .select('id, image_url, processed_image_url, crop_confidence, aspect_ratio, likely_ruler, likely_tag, likely_invalid, has_meat_tones, is_grayscale') \\\n",
    "    .eq('crop_processed', True) \\\n",
    "    .eq('likely_invalid', True) \\\n",
    "    .order('crop_confidence') \\\n",
    "    .execute()\n",
    "\n",
    "invalid_images = response.data\n",
    "print(f\"Found {len(invalid_images)} images flagged as likely invalid\\n\")\n",
    "\n",
    "if len(invalid_images) > 0:\n",
    "    # Categorize by type\n",
    "    rulers = [img for img in invalid_images if img.get('likely_ruler')]\n",
    "    tags = [img for img in invalid_images if img.get('likely_tag') and not img.get('likely_ruler')]\n",
    "    \n",
    "    print(f\"üìè Likely Rulers: {len(rulers)}\")\n",
    "    print(f\"üè∑Ô∏è  Likely Tags: {len(tags)}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"LIKELY RULERS (extreme aspect ratio + grayscale):\")\n",
    "    print(\"=\"*80)\n",
    "    for img in rulers[:10]:\n",
    "        print(f\"  ID: {img['id']}\")\n",
    "        print(f\"    Aspect Ratio: {img['aspect_ratio']:.1f}:1\")\n",
    "        print(f\"    Confidence: {img['crop_confidence']:.1%}\")\n",
    "        print(f\"    Grayscale: {img['is_grayscale']}\")\n",
    "        print(f\"    Processed: {img['processed_image_url']}\")\n",
    "        print()\n",
    "    \n",
    "    if len(rulers) > 10:\n",
    "        print(f\"  ... and {len(rulers) - 10} more\")\n",
    "    \n",
    "    print()\n",
    "    print(\"=\"*80)\n",
    "    print(\"LIKELY TAGS (small size or alphanumeric IDs):\")\n",
    "    print(\"=\"*80)\n",
    "    for img in tags[:10]:\n",
    "        print(f\"  ID: {img['id']}\")\n",
    "        print(f\"    Aspect Ratio: {img['aspect_ratio']:.1f}:1\")\n",
    "        print(f\"    Confidence: {img['crop_confidence']:.1%}\")\n",
    "        print(f\"    Has Meat Tones: {img['has_meat_tones']}\")\n",
    "        print(f\"    Processed: {img['processed_image_url']}\")\n",
    "        print()\n",
    "    \n",
    "    if len(tags) > 10:\n",
    "        print(f\"  ... and {len(tags) - 10} more\")\n",
    "    \n",
    "    print()\n",
    "    print(\"=\"*80)\n",
    "    print(\"SUMMARY:\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total flagged: {len(invalid_images)}\")\n",
    "    print(f\"  - Rulers: {len(rulers)}\")\n",
    "    print(f\"  - Tags: {len(tags)}\")\n",
    "    print()\n",
    "    print(\"üí° Review these images at: https://msl-tender.vercel.app/admin/crop-test\")\n",
    "    print(\"   You can filter by 'likely_invalid=true' to see all flagged images\")\n",
    "else:\n",
    "    print(\"‚úì No images flagged as likely invalid!\")\n",
    "    print(\"   All processed images appear to be valid chops.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ecd792",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üóÑÔ∏è ARCHIVE: One-Time Operations (Already Executed)\n",
    "\n",
    "‚ö†Ô∏è **WARNING: These operations delete data and should only be run when completely restarting from scratch.**\n",
    "\n",
    "These cells have already been executed during initial setup and should not be run again unless you want to wipe all processed images and restart the entire pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4673d84",
   "metadata": {},
   "source": [
    "### A1. Delete All R2 Processed Images\n",
    "\n",
    "‚ö†Ô∏è **DESTRUCTIVE OPERATION** - Deletes ALL files in `processed/` folder on R2.\n",
    "\n",
    "**When to use:** Only if starting completely fresh (e.g., algorithm changed fundamentally).\n",
    "\n",
    "**Status:** Already executed once. Unlikely to need again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c161b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_r2_processed_folder():\n",
    "    \"\"\"Delete all objects in the processed/ folder on R2.\"\"\"\n",
    "    print(\"‚ö†Ô∏è  DELETING ALL PROCESSED IMAGES FROM R2...\")\n",
    "    print(\"    This cannot be undone!\")\n",
    "    \n",
    "    deleted_count = 0\n",
    "    continuation_token = None\n",
    "    \n",
    "    while True:\n",
    "        # List objects in processed/ folder\n",
    "        list_params = {\n",
    "            'Bucket': os.environ['R2_BUCKET_NAME'],\n",
    "            'Prefix': 'processed/'\n",
    "        }\n",
    "        \n",
    "        if continuation_token:\n",
    "            list_params['ContinuationToken'] = continuation_token\n",
    "        \n",
    "        response = r2.list_objects_v2(**list_params)\n",
    "        \n",
    "        if 'Contents' not in response or len(response['Contents']) == 0:\n",
    "            break\n",
    "        \n",
    "        # Delete objects in batches of 1000\n",
    "        objects_to_delete = [{'Key': obj['Key']} for obj in response['Contents']]\n",
    "        \n",
    "        if objects_to_delete:\n",
    "            r2.delete_objects(\n",
    "                Bucket=os.environ['R2_BUCKET_NAME'],\n",
    "                Delete={'Objects': objects_to_delete}\n",
    "            )\n",
    "            deleted_count += len(objects_to_delete)\n",
    "            print(f\"  Deleted {deleted_count} files so far...\")\n",
    "        \n",
    "        # Check if there are more objects to list\n",
    "        if response.get('IsTruncated'):\n",
    "            continuation_token = response.get('NextContinuationToken')\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    print(f\"‚úì Cleanup complete! Deleted {deleted_count} files from processed/ folder\")\n",
    "    return deleted_count\n",
    "\n",
    "# Uncomment to run (requires manual confirmation):\n",
    "# cleanup_r2_processed_folder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef2f396",
   "metadata": {},
   "source": [
    "### A2. Reset Database Records to Unprocessed\n",
    "\n",
    "‚ö†Ô∏è **DESTRUCTIVE OPERATION** - Resets ALL processed records in database to unprocessed state.\n",
    "\n",
    "**When to use:** After running R2 cleanup above, to sync database with empty R2 storage.\n",
    "\n",
    "**Status:** Already executed once. Unlikely to need again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91afbca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset all processed records to unprocessed state\n",
    "result = supabase.table('sample_images') \\\n",
    "    .update({\n",
    "        'crop_processed': False,\n",
    "        'processed_image_url': None,\n",
    "        'crop_x1': None,\n",
    "        'crop_y1': None,\n",
    "        'crop_x2': None,\n",
    "        'crop_y2': None,\n",
    "        'crop_confidence': None,\n",
    "        'processed_at': None\n",
    "    }) \\\n",
    "    .eq('crop_processed', True) \\\n",
    "    .execute()\n",
    "\n",
    "print(f\"‚úì Reset {len(result.data)} processed records to unprocessed state\")\n",
    "\n",
    "# Uncomment to run (requires manual confirmation):\n",
    "# result = supabase.table('sample_images').update({...}).eq('crop_processed', True).execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053cc461",
   "metadata": {},
   "source": [
    "## Export Missing Image Filenames for Deletion (Standalone)\n",
    "\n",
    "**Run ONLY Cell 4 (credentials) first, then run this cell.**\n",
    "\n",
    "This cell checks which database records point to missing R2 files by making HEAD requests. Installs its own dependencies and initializes its own Supabase client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffe5abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies for this cell\n",
    "!pip install -q supabase requests tqdm\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "from supabase import create_client\n",
    "\n",
    "# Initialize Supabase client directly in this cell (standalone)\n",
    "supabase_standalone = create_client(\n",
    "    os.environ['SUPABASE_URL'],\n",
    "    os.environ['SUPABASE_SERVICE_KEY']\n",
    ")\n",
    "\n",
    "print(\"Checking R2 file existence for all database records...\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "# Fetch all records with image_urls (no limit - get all records)\n",
    "response = supabase_standalone.table('sample_images') \\\n",
    "    .select('id, image_url') \\\n",
    "    .not_.is_('image_url', 'null') \\\n",
    "    .limit(10000) \\\n",
    "    .execute()\n",
    "\n",
    "all_records = response.data\n",
    "print(f\"Found {len(all_records)} records to check\\n\")\n",
    "\n",
    "missing_files = []\n",
    "\n",
    "# Check each URL to see if the file exists on R2\n",
    "for record in tqdm(all_records, desc=\"Checking R2 files\"):\n",
    "    try:\n",
    "        # Make HEAD request to check if file exists (faster than GET)\n",
    "        head_response = requests.head(record['image_url'], timeout=5)\n",
    "        \n",
    "        if head_response.status_code == 404:\n",
    "            # File doesn't exist\n",
    "            filename = record['image_url'].split('/')[-1]\n",
    "            missing_files.append({\n",
    "                'id': record['id'],\n",
    "                'filename': filename,\n",
    "                'url': record['image_url']\n",
    "            })\n",
    "    except Exception as e:\n",
    "        # Network error or timeout - treat as potential missing file\n",
    "        filename = record['image_url'].split('/')[-1]\n",
    "        missing_files.append({\n",
    "            'id': record['id'],\n",
    "            'filename': filename,\n",
    "            'url': record['image_url'],\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "# Display results\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(f\"MISSING IMAGE FILENAMES ({len(missing_files)} total):\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "if len(missing_files) > 0:\n",
    "    for item in missing_files:\n",
    "        print(f\"  {item['filename']}\")\n",
    "        if 'error' in item:\n",
    "            print(f\"    (Error: {item['error']})\")\n",
    "    \n",
    "    print()\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total: {len(missing_files)} missing image files\")\n",
    "    print()\n",
    "    print(\"Copy the filenames above and share with me to create a deletion script.\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"‚úì No missing files found! All database records point to existing R2 files.\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e6ef75",
   "metadata": {},
   "source": [
    "## Verify Missing Images (R2 Direct Check)\n",
    "\n",
    "**IMPORTANT:** Run this to verify that \"missing\" images are truly missing and not false positives.\n",
    "\n",
    "This checks R2 directly using boto3 to confirm 404 errors are real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bdf815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total files in R2 original/ folder\n",
    "print(\"Counting files in R2 original/ folder...\")\n",
    "paginator = r2.get_paginator('list_objects_v2')\n",
    "pages = paginator.paginate(Bucket=os.environ['R2_BUCKET_NAME'], Prefix='original/')\n",
    "\n",
    "r2_file_count = 0\n",
    "for page in pages:\n",
    "    if 'Contents' in page:\n",
    "        r2_file_count += len(page['Contents'])\n",
    "\n",
    "print(f\"‚úì Total files in R2 original/: {r2_file_count}\")\n",
    "print(f\"‚úì Total database records: 1412\")\n",
    "print(f\"‚úì Expected missing (78 + 316): 394\")\n",
    "print(f\"‚úì Expected R2 files: {1412 - 394} = 1018\")\n",
    "print()\n",
    "\n",
    "# Verify \"missing\" images by checking R2 directly\n",
    "if 'results' in locals() and len(results.get('missing_ids', [])) > 0:\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Verifying ALL {len(results['missing_ids'])} 'missing' images...\")\n",
    "    print(\"This will take a few minutes...\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    false_positives = []\n",
    "    confirmed_missing = []\n",
    "    \n",
    "    for img_id in tqdm(results['missing_ids'], desc=\"Checking all images\"):  # Check ALL\n",
    "        # Get URL from database\n",
    "        response = supabase.table('sample_images').select('image_url').eq('id', str(img_id)).execute()\n",
    "        if response.data:\n",
    "            url = response.data[0]['image_url']\n",
    "            filename = url.split('/')[-1]\n",
    "            \n",
    "            # Check if file exists in R2 directly\n",
    "            try:\n",
    "                r2.head_object(Bucket=os.environ['R2_BUCKET_NAME'], Key=f'original/{filename}')\n",
    "                false_positives.append(filename)\n",
    "                print(f\"‚ö†Ô∏è  FALSE POSITIVE: {filename} EXISTS in R2!\")\n",
    "            except:\n",
    "                confirmed_missing.append(filename)\n",
    "    \n",
    "    print()\n",
    "    print(\"=\"*80)\n",
    "    print(f\"FINAL VERIFICATION RESULTS:\")\n",
    "    print(f\"  ‚úÖ Confirmed missing: {len(confirmed_missing)}\")\n",
    "    print(f\"  ‚ö†Ô∏è  False positives: {len(false_positives)}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if len(false_positives) > 0:\n",
    "        print()\n",
    "        print(\"‚ö†Ô∏è  WARNING: False positives detected!\")\n",
    "        print(\"    Files exist in R2 but were reported as 404\")\n",
    "        print(\"    DO NOT DELETE THESE RECORDS!\")\n",
    "        print()\n",
    "        print(\"False positive files:\")\n",
    "        for fp in false_positives[:20]:  # Show first 20\n",
    "            print(f\"  - {fp}\")\n",
    "        if len(false_positives) > 20:\n",
    "            print(f\"  ... and {len(false_positives) - 20} more\")\n",
    "    else:\n",
    "        print()\n",
    "        print(\"‚úÖ All 'missing' images confirmed as truly missing from R2\")\n",
    "        print(\"   Safe to proceed with deletion of these orphaned records\")\n",
    "else:\n",
    "    print(\"No 'results' variable found. Run Cell 13 first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cfdbbd",
   "metadata": {},
   "source": [
    "## üö® CRITICAL AUDIT: R2 vs Database Mismatch\n",
    "\n",
    "**PROBLEM:** R2 has 1,490 files, but 394 database records point to \"missing\" files.\n",
    "\n",
    "This cell will:\n",
    "1. List ALL filenames actually in R2 original/ folder\n",
    "2. List ALL filenames from database image_url fields\n",
    "3. Compare to find mismatches and orphaned files\n",
    "4. Identify if there's a naming pattern issue (case, extension, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dd2f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE R2 vs DATABASE AUDIT\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Step 1: Get ALL filenames from R2 original/ folder\n",
    "print(\"Step 1: Fetching ALL files from R2 original/ folder...\")\n",
    "paginator = r2.get_paginator('list_objects_v2')\n",
    "pages = paginator.paginate(Bucket=os.environ['R2_BUCKET_NAME'], Prefix='original/')\n",
    "\n",
    "r2_filenames = set()\n",
    "for page in pages:\n",
    "    if 'Contents' in page:\n",
    "        for obj in page['Contents']:\n",
    "            # Extract just the filename (remove 'original/' prefix)\n",
    "            key = obj['Key']\n",
    "            if key.startswith('original/'):\n",
    "                filename = key[len('original/'):]\n",
    "                if filename:  # Skip if it's just the folder itself\n",
    "                    r2_filenames.add(filename)\n",
    "\n",
    "print(f\"‚úì Found {len(r2_filenames)} files in R2 original/ folder\")\n",
    "print()\n",
    "\n",
    "# Step 2: Get ALL filenames from database with proper pagination\n",
    "print(\"Step 2: Fetching ALL database image_url filenames with pagination...\")\n",
    "db_filenames = set()\n",
    "page_size = 1000\n",
    "offset = 0\n",
    "\n",
    "while True:\n",
    "    response = supabase.table('sample_images') \\\n",
    "        .select('image_url') \\\n",
    "        .not_.is_('image_url', 'null') \\\n",
    "        .range(offset, offset + page_size - 1) \\\n",
    "        .execute()\n",
    "    \n",
    "    if not response.data or len(response.data) == 0:\n",
    "        break\n",
    "    \n",
    "    for record in response.data:\n",
    "        url = record['image_url']\n",
    "        filename = url.split('/')[-1]\n",
    "        db_filenames.add(filename)\n",
    "    \n",
    "    print(f\"  Fetched {len(response.data)} records (total so far: {len(db_filenames)})\")\n",
    "    \n",
    "    if len(response.data) < page_size:\n",
    "        break\n",
    "    \n",
    "    offset += page_size\n",
    "\n",
    "print(f\"‚úì Found {len(db_filenames)} image URLs in database\")\n",
    "print()\n",
    "\n",
    "# Step 3: Compare the two sets\n",
    "print(\"=\"*80)\n",
    "print(\"COMPARISON RESULTS:\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Files in R2 but NOT in database (orphaned R2 files)\n",
    "orphaned_r2_files = r2_filenames - db_filenames\n",
    "print(f\"üìÅ Files in R2 but NOT in database: {len(orphaned_r2_files)}\")\n",
    "if len(orphaned_r2_files) > 0:\n",
    "    print(\"   First 20 orphaned R2 files:\")\n",
    "    for filename in sorted(list(orphaned_r2_files))[:20]:\n",
    "        print(f\"     - {filename}\")\n",
    "    if len(orphaned_r2_files) > 20:\n",
    "        print(f\"     ... and {len(orphaned_r2_files) - 20} more\")\n",
    "print()\n",
    "\n",
    "# Files in database but NOT in R2 (missing files)\n",
    "missing_from_r2 = db_filenames - r2_filenames\n",
    "print(f\"‚ùå Files in database but NOT in R2: {len(missing_from_r2)}\")\n",
    "if len(missing_from_r2) > 0:\n",
    "    print(\"   First 20 missing files:\")\n",
    "    for filename in sorted(list(missing_from_r2))[:20]:\n",
    "        print(f\"     - {filename}\")\n",
    "    if len(missing_from_r2) > 20:\n",
    "        print(f\"     ... and {len(missing_from_r2) - 20} more\")\n",
    "print()\n",
    "\n",
    "# Files that match (exist in both)\n",
    "matching_files = r2_filenames & db_filenames\n",
    "print(f\"‚úÖ Files that match (in both R2 and database): {len(matching_files)}\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SUMMARY:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"R2 total files:        {len(r2_filenames)}\")\n",
    "print(f\"Database total URLs:   {len(db_filenames)}\")\n",
    "print(f\"Matching:              {len(matching_files)}\")\n",
    "print(f\"Orphaned in R2:        {len(orphaned_r2_files)}\")\n",
    "print(f\"Missing from R2:       {len(missing_from_r2)}\")\n",
    "print()\n",
    "\n",
    "# Step 4: Pattern analysis\n",
    "if len(orphaned_r2_files) > 0 and len(missing_from_r2) > 0:\n",
    "    print(\"=\"*80)\n",
    "    print(\"PATTERN ANALYSIS:\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "    \n",
    "    # Check for case sensitivity issues\n",
    "    r2_lower = {f.lower(): f for f in r2_filenames}\n",
    "    db_lower = {f.lower(): f for f in db_filenames}\n",
    "    \n",
    "    case_mismatches = []\n",
    "    for db_file in missing_from_r2:\n",
    "        if db_file.lower() in r2_lower and r2_lower[db_file.lower()] in orphaned_r2_files:\n",
    "            case_mismatches.append({\n",
    "                'db': db_file,\n",
    "                'r2': r2_lower[db_file.lower()]\n",
    "            })\n",
    "    \n",
    "    if len(case_mismatches) > 0:\n",
    "        print(f\"‚ö†Ô∏è  CASE SENSITIVITY MISMATCH DETECTED!\")\n",
    "        print(f\"   Found {len(case_mismatches)} files with case differences:\")\n",
    "        for match in case_mismatches[:10]:\n",
    "            print(f\"     Database: {match['db']}\")\n",
    "            print(f\"     R2:       {match['r2']}\")\n",
    "            print()\n",
    "        if len(case_mismatches) > 10:\n",
    "            print(f\"     ... and {len(case_mismatches) - 10} more\")\n",
    "    \n",
    "    # Check for extension differences (.JPG vs .jpg vs .jpeg)\n",
    "    print()\n",
    "    print(\"Extension analysis:\")\n",
    "    db_extensions = {}\n",
    "    r2_extensions = {}\n",
    "    \n",
    "    for f in db_filenames:\n",
    "        ext = f.split('.')[-1].lower() if '.' in f else 'none'\n",
    "        db_extensions[ext] = db_extensions.get(ext, 0) + 1\n",
    "    \n",
    "    for f in r2_filenames:\n",
    "        ext = f.split('.')[-1].lower() if '.' in f else 'none'\n",
    "        r2_extensions[ext] = r2_extensions.get(ext, 0) + 1\n",
    "    \n",
    "    print(f\"  Database extensions: {db_extensions}\")\n",
    "    print(f\"  R2 extensions:       {r2_extensions}\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"NEXT STEPS:\")\n",
    "print(\"=\"*80)\n",
    "if len(orphaned_r2_files) == len(missing_from_r2):\n",
    "    print(\"‚úì Orphaned R2 files count MATCHES missing database files count!\")\n",
    "    print(\"  This suggests a systematic mismatch (possibly case or naming issue)\")\n",
    "    print(\"  DO NOT DELETE ANY RECORDS - files exist but with different names\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Counts don't match:\")\n",
    "    print(f\"   Orphaned in R2: {len(orphaned_r2_files)}\")\n",
    "    print(f\"   Missing from R2: {len(missing_from_r2)}\")\n",
    "    if len(missing_from_r2) == 0:\n",
    "        print()\n",
    "        print(\"‚úì GOOD NEWS: All database records point to existing R2 files!\")\n",
    "        print(f\"   The {len(orphaned_r2_files)} orphaned R2 files have no database records\")\n",
    "        print(f\"   These are the files from the 78 deleted records + others\")\n",
    "    else:\n",
    "        print(f\"   Need further investigation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8099aa41",
   "metadata": {},
   "source": [
    "## ‚úÖ SOLUTION: Extension Mismatch (.JPG vs .JPEG)\n",
    "\n",
    "**ROOT CAUSE IDENTIFIED:**\n",
    "- Database points to `.JPG` extension\n",
    "- R2 actually has `.JPEG` extension for 394 files\n",
    "- 316 database records need URL updates (78 already deleted by mistake)\n",
    "\n",
    "This cell will verify the mismatch and show which records need fixing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c684ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"EXTENSION MISMATCH VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Check if missing database files would match if we change .JPG to .JPEG\n",
    "print(\"Checking if 'missing' files exist with .JPEG extension instead...\")\n",
    "print()\n",
    "\n",
    "extension_mismatches = []\n",
    "\n",
    "for db_file in sorted(list(missing_from_r2)):\n",
    "    # Replace .JPG with .JPEG\n",
    "    jpeg_version = db_file.replace('.JPG', '.JPEG')\n",
    "    \n",
    "    if jpeg_version in orphaned_r2_files:\n",
    "        extension_mismatches.append({\n",
    "            'db_filename': db_file,\n",
    "            'r2_filename': jpeg_version\n",
    "        })\n",
    "\n",
    "print(f\"‚úÖ Found {len(extension_mismatches)} files with extension mismatch!\")\n",
    "print(f\"   Database points to: .JPG\")\n",
    "print(f\"   R2 actually has:   .JPEG\")\n",
    "print()\n",
    "\n",
    "if len(extension_mismatches) > 0:\n",
    "    print(\"First 20 mismatches:\")\n",
    "    for match in extension_mismatches[:20]:\n",
    "        print(f\"  Database: {match['db_filename']}\")\n",
    "        print(f\"  R2:       {match['r2_filename']}\")\n",
    "        print()\n",
    "    \n",
    "    if len(extension_mismatches) > 20:\n",
    "        print(f\"  ... and {len(extension_mismatches) - 20} more\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"CRITICAL FINDINGS:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"‚úÖ {len(extension_mismatches)} of 316 'missing' files are NOT actually missing!\")\n",
    "print(f\"   They exist in R2 with .JPEG extension instead of .JPG\")\n",
    "print()\n",
    "\n",
    "not_explained = 316 - len(extension_mismatches)\n",
    "if not_explained > 0:\n",
    "    print(f\"‚ö†Ô∏è  {not_explained} files still unexplained - need investigation\")\n",
    "else:\n",
    "    print(f\"‚úÖ ALL 316 'missing' files accounted for!\")\n",
    "    print()\n",
    "    print(\"NEXT STEPS:\")\n",
    "    print(\"1. Update database URLs from .JPG to .JPEG for these 316 records\")\n",
    "    print(\"2. Check if the 78 deleted records can be restored (likely also .JPEG)\")\n",
    "    print()\n",
    "    print(\"‚ö†Ô∏è  DO NOT DELETE ANY RECORDS - This is a URL update issue, not missing files!\")\n",
    "\n",
    "# Store for later use\n",
    "extension_mismatch_list = extension_mismatches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c5a458",
   "metadata": {},
   "source": [
    "## üîÑ STEP 1: Verify 78 Deleted Files Exist as .JPEG\n",
    "\n",
    "Check if all 78 deleted filenames exist in R2 with .JPEG extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f53660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 78 deleted filenames (from delete_orphaned_records_final.sql)\n",
    "deleted_filenames = [\n",
    "    '2304B00C0196D00.JPG', '2205B02C2209D01.JPG', '2205B01C2022D01.JPG', '2205B01C2043D01.JPG',\n",
    "    '2205B02C2210D01.JPG', '2205B01C8115D01.JPG', '2205B02C2202D01.JPG', '2205B01C8050D01.JPG',\n",
    "    '2205B02C2170D01.JPG', '2205B02C2194D01.JPG', '2205B01C2083D01.JPG', '2205B02C2197D01.JPG',\n",
    "    '2205B02C2227D01.JPG', '2205B02C8165D01.JPG', '2304B00C0197D00.JPG', '2205B01C8037D01.JPG',\n",
    "    '2205B01C8077D01.JPG', '2205B02C2186D01.JPG', '2205B02C8136D01.JPG', '2205B01C2069D01.JPG',\n",
    "    '2205B02C2118D01.JPG', '2205B02C8163D01.JPG', '2205B02C8203D01.JPG', '2205B02C8238D01.JPG',\n",
    "    '2205B02C8239D01.JPG', '2205B02C2187D01.JPG', '2205B01C2106D01.JPG', '2205B01C8041D01.JPG',\n",
    "    '2205B01C8036D01.JPG', '2205B02C8208D01.JPG', '2205B01C2006D01.JPG', '2205B01C8025D01.JPG',\n",
    "    '2205B01C8109D01.JPG', '2205B01C8127D01.JPG', '2205B02C2198D01.JPG', '2205B02C8190D01.JPG',\n",
    "    '2205B01C2002D01.JPG', '2205B01C2015D01.JPG', '2205B01C2046D01.JPG', '2205B01C2068D01.JPG',\n",
    "    '2205B01C8016D01.JPG', '2205B02C2148D01.JPG', '2205B02C2206D01.JPG', '2205B02C2215D01.JPG',\n",
    "    '2205B02C8201D01.JPG', '2205B01C2014D01.JPG', '2205B01C8032D01.JPG', '2205B01C8042D01.JPG',\n",
    "    '2205B01C8130D01.JPG', '2205B02C2171D01.JPG', '2205B02C8173D01.JPG', '2205B02C8253D01.JPG',\n",
    "    '2205B02C8250D01.JPG', '2205B01C8063D01.JPG', '2205B02C8183D01.JPG', '2205B02C8224D01.JPG',\n",
    "    '2205B01C2095D01.JPG', '2205B01C8020D01.JPG', '2205B01C8105D01.JPG', '2205B01C8107D01.JPG',\n",
    "    '2205B02C8161D01.JPG', '2205B02C8209D01.JPG', '2205B01C2091D01.JPG', '2205B01C8007D01.JPG',\n",
    "    '2205B01C2053D01.JPG', '2205B01C2017D01.JPG', '2205B01C8001D01.JPG', '2205B01C8073D01.JPG',\n",
    "    '2205B02C2131D01.JPG', '2205B02C2155D01.JPG', '2205B01C2001D01.JPG', '2205B01C2104D01.JPG',\n",
    "    '2205B02C2150D01.JPG', '2205B01C2048D01.JPG', '2205B02C8149D01.JPG', '2205B02C8202D01.JPG',\n",
    "    '2205B02C8205D01.JPG', '2205B02C8215D01.JPG'\n",
    "]\n",
    "\n",
    "print(f\"Checking if all 78 deleted files exist in R2 with .JPEG extension...\")\n",
    "print()\n",
    "\n",
    "found_in_r2 = []\n",
    "not_found = []\n",
    "\n",
    "for filename in deleted_filenames:\n",
    "    # Replace .JPG with .JPEG\n",
    "    jpeg_version = filename.replace('.JPG', '.JPEG')\n",
    "    \n",
    "    # Check if it exists in orphaned_r2_files set from previous cell\n",
    "    if jpeg_version in orphaned_r2_files:\n",
    "        found_in_r2.append(jpeg_version)\n",
    "    else:\n",
    "        not_found.append(filename)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"‚úÖ Found {len(found_in_r2)} of 78 deleted files in R2 (as .JPEG)\")\n",
    "print(f\"‚ùå Not found: {len(not_found)}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(not_found) > 0:\n",
    "    print()\n",
    "    print(\"‚ö†Ô∏è  Files not found in R2:\")\n",
    "    for f in not_found:\n",
    "        print(f\"  - {f}\")\n",
    "else:\n",
    "    print()\n",
    "    print(\"‚úÖ ALL 78 deleted files confirmed to exist in R2 as .JPEG!\")\n",
    "    print()\n",
    "    print(\"Ready to restore these 78 records to the database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fb203a",
   "metadata": {},
   "source": [
    "## üîÑ STEP 2: Generate SQL to Restore 78 Deleted Records\n",
    "\n",
    "This will create an INSERT statement to restore the deleted records with correct .JPEG URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c428a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Restoring 78 deleted records from original CSV data...\")\n",
    "print()\n",
    "\n",
    "# Extract study numbers from deleted filenames\n",
    "study_numbers_to_restore = []\n",
    "for filename in deleted_filenames:\n",
    "    study_number = filename.replace('.JPG', '')\n",
    "    study_numbers_to_restore.append(study_number)\n",
    "\n",
    "print(f\"Study numbers to restore: {len(study_numbers_to_restore)}\")\n",
    "print()\n",
    "\n",
    "# Query pork_samples to get the sample_id for each study_number\n",
    "print(\"Looking up sample_ids from pork_samples table...\")\n",
    "restored_count = 0\n",
    "already_exists_count = 0\n",
    "not_found_count = 0\n",
    "errors = []\n",
    "\n",
    "for study_num in tqdm(study_numbers_to_restore, desc=\"Restoring records\"):\n",
    "    try:\n",
    "        # Look up the sample in pork_samples\n",
    "        sample_result = supabase.table('pork_samples') \\\n",
    "            .select('id, study_number') \\\n",
    "            .eq('study_number', study_num) \\\n",
    "            .execute()\n",
    "        \n",
    "        if not sample_result.data or len(sample_result.data) == 0:\n",
    "            not_found_count += 1\n",
    "            errors.append(f\"Study number not found in pork_samples: {study_num}\")\n",
    "            continue\n",
    "        \n",
    "        sample_id = sample_result.data[0]['id']\n",
    "        \n",
    "        # Check if record already exists\n",
    "        existing_check = supabase.table('sample_images') \\\n",
    "            .select('id') \\\n",
    "            .eq('sample_id', sample_id) \\\n",
    "            .execute()\n",
    "        \n",
    "        if existing_check.data and len(existing_check.data) > 0:\n",
    "            already_exists_count += 1\n",
    "            continue\n",
    "        \n",
    "        # Insert the record with .JPEG extension\n",
    "        image_url = f\"{os.environ['R2_PUBLIC_URL']}/original/{study_num}.JPEG\"\n",
    "        \n",
    "        insert_result = supabase.table('sample_images').insert({\n",
    "            'sample_id': sample_id,\n",
    "            'image_url': image_url,\n",
    "            'image_type': 'chop'\n",
    "        }).execute()\n",
    "        \n",
    "        restored_count += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        errors.append(f\"Error restoring {study_num}: {str(e)}\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"RESTORATION RESULTS:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"‚úÖ Successfully restored: {restored_count}\")\n",
    "print(f\"‚ö†Ô∏è  Already exists: {already_exists_count}\")\n",
    "print(f\"‚ùå Not found in pork_samples: {not_found_count}\")\n",
    "print()\n",
    "\n",
    "if len(errors) > 0:\n",
    "    print(\"Errors encountered:\")\n",
    "    for error in errors[:10]:\n",
    "        print(f\"  - {error}\")\n",
    "    if len(errors) > 10:\n",
    "        print(f\"  ... and {len(errors) - 10} more\")\n",
    "    print()\n",
    "\n",
    "# Verify total count\n",
    "verify_result = supabase.table('sample_images') \\\n",
    "    .select('id', count='exact') \\\n",
    "    .execute()\n",
    "\n",
    "print(f\"Total sample_images records after restoration: {verify_result.count}\")\n",
    "print()\n",
    "print(\"NEXT: Run STEP 3 to update the 316 existing URLs from .JPG to .JPEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea2bedc",
   "metadata": {},
   "source": [
    "## üîÑ STEP 3: Generate SQL to Update 316 Existing URLs\n",
    "\n",
    "Update the 316 records that currently point to .JPG to use .JPEG extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41597188",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating SQL to update 316 existing records from .JPG to .JPEG...\")\n",
    "print()\n",
    "\n",
    "# Use the extension_mismatch_list from previous cell\n",
    "if 'extension_mismatch_list' not in locals() or len(extension_mismatch_list) == 0:\n",
    "    print(\"‚ö†Ô∏è  extension_mismatch_list not found!\")\n",
    "    print(\"   Run the extension verification cell first.\")\n",
    "else:\n",
    "    update_sql_lines = []\n",
    "    update_sql_lines.append(\"-- Update 316 records to use .JPEG extension instead of .JPG\")\n",
    "    update_sql_lines.append(\"-- Run this SQL in Supabase SQL Editor\")\n",
    "    update_sql_lines.append(\"\")\n",
    "    update_sql_lines.append(f\"-- Total records to update: {len(extension_mismatch_list)}\")\n",
    "    update_sql_lines.append(\"\")\n",
    "    \n",
    "    # Generate UPDATE statement using REPLACE\n",
    "    update_sql_lines.append(\"-- Update all records where image_url ends with .JPG but should be .JPEG\")\n",
    "    update_sql_lines.append(\"UPDATE sample_images\")\n",
    "    update_sql_lines.append(\"SET image_url = REPLACE(image_url, '.JPG', '.JPEG')\")\n",
    "    update_sql_lines.append(\"WHERE image_url LIKE '%' || ('.JPG')\")\n",
    "    update_sql_lines.append(\"  AND image_url IN (\")\n",
    "    \n",
    "    # Add specific URLs to update (using LIKE patterns for safety)\n",
    "    for i, match in enumerate(extension_mismatch_list):\n",
    "        db_filename = match['db_filename']\n",
    "        if i < len(extension_mismatch_list) - 1:\n",
    "            update_sql_lines.append(f\"    '{os.environ['R2_PUBLIC_URL']}/original/{db_filename}',\")\n",
    "        else:\n",
    "            update_sql_lines.append(f\"    '{os.environ['R2_PUBLIC_URL']}/original/{db_filename}'\")\n",
    "    \n",
    "    update_sql_lines.append(\"  );\")\n",
    "    update_sql_lines.append(\"\")\n",
    "    update_sql_lines.append(\"-- Verify update\")\n",
    "    update_sql_lines.append(\"SELECT \")\n",
    "    update_sql_lines.append(\"  COUNT(*) FILTER (WHERE image_url LIKE '%.JPEG') as jpeg_count,\")\n",
    "    update_sql_lines.append(\"  COUNT(*) FILTER (WHERE image_url LIKE '%.JPG') as jpg_count,\")\n",
    "    update_sql_lines.append(\"  COUNT(*) as total_count\")\n",
    "    update_sql_lines.append(\"FROM sample_images;\")\n",
    "    update_sql_lines.append(\"\")\n",
    "    update_sql_lines.append(\"-- Expected after update:\")\n",
    "    update_sql_lines.append(f\"--   jpeg_count: {394 + 78} (394 current + 78 restored)\")\n",
    "    update_sql_lines.append(f\"--   jpg_count:  {1096}\")\n",
    "    update_sql_lines.append(f\"--   total:      {1490}\")\n",
    "    \n",
    "    update_sql = '\\n'.join(update_sql_lines)\n",
    "    \n",
    "    # Save to file\n",
    "    with open('/content/update_316_urls_to_jpeg.sql', 'w') as f:\n",
    "        f.write(update_sql)\n",
    "    \n",
    "    print(\"‚úÖ SQL script generated!\")\n",
    "    print()\n",
    "    print(\"=\"*80)\n",
    "    print(\"UPDATE SQL SCRIPT:\")\n",
    "    print(\"=\"*80)\n",
    "    print(update_sql)\n",
    "    print()\n",
    "    print(\"=\"*80)\n",
    "    print(\"üìù Script saved to: /content/update_316_urls_to_jpeg.sql\")\n",
    "    print()\n",
    "    print(\"NEXT: Copy this SQL and run it in Supabase SQL Editor AFTER restoring 78 records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ea3041",
   "metadata": {},
   "source": [
    "## Backfill Enhanced Metrics for Already-Processed Images\n",
    "\n",
    "This cell updates enhanced metrics (aspect ratio, color analysis, text patterns, validity flags) for images that were processed BEFORE these metrics were added. It analyzes the already-processed images without re-running rembg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f91b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_processed_image(image: Image.Image) -> dict:\n",
    "    \"\"\"\n",
    "    Analyze an already-processed image to extract enhanced metrics.\n",
    "    Does NOT re-run rembg - just analyzes existing processed image.\n",
    "    \n",
    "    Returns dict with enhanced metrics.\n",
    "    \"\"\"\n",
    "    # Convert to RGB and numpy array\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    \n",
    "    img_array = np.array(image)\n",
    "    height, width = img_array.shape[:2]\n",
    "    \n",
    "    # Create mask: non-white pixels = foreground\n",
    "    # White background has RGB values close to 255\n",
    "    white_threshold = 240\n",
    "    is_foreground = ~((img_array[:, :, 0] > white_threshold) & \n",
    "                      (img_array[:, :, 1] > white_threshold) & \n",
    "                      (img_array[:, :, 2] > white_threshold))\n",
    "    \n",
    "    # Get bounding box\n",
    "    rows = np.any(is_foreground, axis=1)\n",
    "    cols = np.any(is_foreground, axis=0)\n",
    "    \n",
    "    if not rows.any() or not cols.any():\n",
    "        return {\n",
    "            'aspect_ratio': None,\n",
    "            'has_meat_tones': False,\n",
    "            'avg_saturation': 0.0,\n",
    "            'is_grayscale': True,\n",
    "            'has_sequential_numbers': False,\n",
    "            'has_alphanumeric_id': False,\n",
    "            'likely_ruler': False,\n",
    "            'likely_tag': False,\n",
    "            'likely_invalid': True\n",
    "        }\n",
    "    \n",
    "    y1, y2 = np.where(rows)[0][[0, -1]]\n",
    "    x1, x2 = np.where(cols)[0][[0, -1]]\n",
    "    \n",
    "    # Crop to foreground\n",
    "    cropped_rgb = img_array[y1:y2+1, x1:x2+1]\n",
    "    cropped_mask = is_foreground[y1:y2+1, x1:x2+1]\n",
    "    \n",
    "    # Calculate dimensions and aspect ratio\n",
    "    crop_width = x2 - x1 + 1\n",
    "    crop_height = y2 - y1 + 1\n",
    "    aspect_ratio = max(crop_width, crop_height) / max(min(crop_width, crop_height), 1)\n",
    "    \n",
    "    # Color analysis\n",
    "    color_metrics = analyze_color_distribution(cropped_rgb, cropped_mask)\n",
    "    \n",
    "    # OCR text analysis\n",
    "    try:\n",
    "        ocr_results = reader.readtext(cropped_rgb, detail=0)\n",
    "        detected_text = ' '.join(ocr_results).strip()\n",
    "        text_patterns = analyze_text_pattern(detected_text)\n",
    "    except Exception as e:\n",
    "        text_patterns = {\n",
    "            'has_sequential_numbers': False,\n",
    "            'has_alphanumeric_id': False,\n",
    "            'has_measurement_marks': False\n",
    "        }\n",
    "    \n",
    "    # Calculate composite validity flags\n",
    "    is_extreme_aspect_ratio = aspect_ratio > 4.0\n",
    "    is_too_small = crop_width < 300 or crop_height < 300\n",
    "    \n",
    "    likely_ruler = (\n",
    "        is_extreme_aspect_ratio and \n",
    "        color_metrics['is_grayscale'] and \n",
    "        text_patterns.get('has_sequential_numbers', False)\n",
    "    )\n",
    "    \n",
    "    likely_tag = (\n",
    "        is_too_small or \n",
    "        text_patterns.get('has_alphanumeric_id', False)\n",
    "    )\n",
    "    \n",
    "    likely_invalid = likely_ruler or likely_tag or (is_extreme_aspect_ratio and not color_metrics['has_meat_tones'])\n",
    "    \n",
    "    return {\n",
    "        'aspect_ratio': float(aspect_ratio),\n",
    "        'has_meat_tones': bool(color_metrics['has_meat_tones']),\n",
    "        'avg_saturation': float(color_metrics['avg_saturation']),\n",
    "        'is_grayscale': bool(color_metrics['is_grayscale']),\n",
    "        'has_sequential_numbers': bool(text_patterns['has_sequential_numbers']),\n",
    "        'has_alphanumeric_id': bool(text_patterns['has_alphanumeric_id']),\n",
    "        'likely_ruler': bool(likely_ruler),\n",
    "        'likely_tag': bool(likely_tag),\n",
    "        'likely_invalid': bool(likely_invalid)\n",
    "    }\n",
    "\n",
    "\n",
    "# Query images that are processed but missing enhanced metrics\n",
    "# Use .limit(2000) to ensure we get all 1490 images (default is 1000)\n",
    "response = supabase.table('sample_images') \\\n",
    "    .select('id, processed_image_url') \\\n",
    "    .eq('crop_processed', True) \\\n",
    "    .is_('aspect_ratio', 'null') \\\n",
    "    .not_.is_('processed_image_url', 'null') \\\n",
    "    .limit(2000) \\\n",
    "    .execute()\n",
    "\n",
    "images_to_backfill = response.data\n",
    "print(f\"Found {len(images_to_backfill)} processed images missing enhanced metrics\")\n",
    "print(f\"(Query limit: 2000, ensures all 1490 images are captured)\\n\")\n",
    "\n",
    "if len(images_to_backfill) > 0:\n",
    "    results = {\n",
    "        'success': 0,\n",
    "        'failed': 0,\n",
    "        'likely_invalid': 0,\n",
    "        'errors': []\n",
    "    }\n",
    "\n",
    "    for img_data in tqdm(images_to_backfill, desc=\"Backfilling enhanced metrics\"):\n",
    "        try:\n",
    "            # Download already-processed image from R2\n",
    "            processed_image = download_image(img_data['processed_image_url'])\n",
    "            \n",
    "            # Analyze to get enhanced metrics\n",
    "            metrics = analyze_processed_image(processed_image)\n",
    "            \n",
    "            # Track likely invalid images\n",
    "            if metrics['likely_invalid']:\n",
    "                results['likely_invalid'] += 1\n",
    "            \n",
    "            # Update database with enhanced metrics only\n",
    "            supabase.table('sample_images').update({\n",
    "                'aspect_ratio': metrics['aspect_ratio'],\n",
    "                'has_meat_tones': metrics['has_meat_tones'],\n",
    "                'avg_saturation': metrics['avg_saturation'],\n",
    "                'is_grayscale': metrics['is_grayscale'],\n",
    "                'has_sequential_numbers': metrics['has_sequential_numbers'],\n",
    "                'likely_ruler': metrics['likely_ruler'],\n",
    "                'likely_tag': metrics['likely_tag'],\n",
    "                'likely_invalid': metrics['likely_invalid']\n",
    "            }).eq('id', img_data['id']).execute()\n",
    "            \n",
    "            results['success'] += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            results['failed'] += 1\n",
    "            results['errors'].append({\n",
    "                'id': img_data['id'],\n",
    "                'url': img_data.get('processed_image_url', 'N/A'),\n",
    "                'error': str(e)\n",
    "            })\n",
    "\n",
    "    print(f\"\\n‚úì Backfill complete: {results['success']} succeeded, {results['failed']} failed\")\n",
    "    print(f\"‚ö†Ô∏è  {results['likely_invalid']} images flagged as likely invalid (rulers/tags)\")\n",
    "    \n",
    "    if results['errors']:\n",
    "        print(f\"\\n‚ùå {len(results['errors'])} errors:\")\n",
    "        for err in results['errors'][:10]:  # Show first 10\n",
    "            print(f\"  ID {err['id']}: {err['error']}\")\n",
    "else:\n",
    "    print(\"‚úì All processed images already have enhanced metrics!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
